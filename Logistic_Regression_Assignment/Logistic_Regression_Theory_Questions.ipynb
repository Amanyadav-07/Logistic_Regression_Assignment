{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOHLKsK6F5eMYm/kSUSwOtv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["##1. What is Logistic Regression, and how does it differ from Linear Regression?"],"metadata":{"id":"QhIP__sraUfW"}},{"cell_type":"markdown","source":["###Ans:- Logistic Regression is a statistical method used for classification problems. It predicts the probability that a given input belongs to a particular category (e.g., spam or not spam, disease or no disease).\n","\n","\n","###Linear Regression is used for predicting continuous values (e.g., predicting house prices based on area, predicting salary based on experience). It finds the best-fitting straight line through the data points.\n","\n","###Differences:-\n","\n","\n","```\n","Logistic Regression:-\n","  1. Classification(yes/no)\n","  2. Probablity(b/w 0 and 1)\n","  3. Sigmoid Function\n","  4. Used to determine the likelihood of a category.\n","\n","Linear Regression:-\n","  1. Regression( Predicting Continuous values)\n","  2. Any Real Number\n","  3. Straight-line equation\n","  4. Used to predict a continuous dependent variable.\n","```\n","\n","\n","\n"],"metadata":{"id":"YV9mNQPvaYmg"}},{"cell_type":"markdown","source":["##2. What is the mathematical equation of Logistic Regression?"],"metadata":{"id":"RMcw4d25b2fA"}},{"cell_type":"markdown","source":["###Ans:- Mathematical equation of Logistic Regression:-\n","p=\n","1/\n","1+e^-(b0‚Äã+b1‚Äãx1+b2‚Äãx2+...+bnxn)\n"],"metadata":{"id":"vdWKu2_XcBBE"}},{"cell_type":"markdown","source":["##3. Why do we use the Sigmoid Function in Logistic Regression?"],"metadata":{"id":"8wBX_4ficmwJ"}},{"cell_type":"markdown","source":["###Ans:- The Sigmoid function is used in Logistic Regression because it helps convert any real number into a probability between 0 and 1, making it suitable for classification problems.\n","\n"],"metadata":{"id":"HBFCUIt5c1ya"}},{"cell_type":"markdown","source":["##4. What is the cost funciton of Logistic Regression?"],"metadata":{"id":"M_x1oiI8c5BM"}},{"cell_type":"markdown","source":["###Ans:- 2. Log Loss (Binary Cross-Entropy) Cost Function\n","The cost function for one training example is:\n","\n","Cost\n","(\n","ùë¶\n","^\n",",\n","ùë¶\n",")\n","=\n","‚àí\n","[\n","ùë¶\n","log\n","‚Å°\n","(\n","ùë¶\n","^\n",")\n","+\n","(\n","1\n","‚àí\n","ùë¶\n",")\n","log\n","‚Å°\n","(\n","1\n","‚àí\n","ùë¶\n","^\n",")\n","]\n","Cost(\n","y\n","^\n","‚Äã\n"," ,y)=‚àí[ylog(\n","y\n","^\n","‚Äã\n"," )+(1‚àíy)log(1‚àí\n","y\n","^\n","‚Äã\n"," )]\n","where:\n","\n","ùë¶\n","y = actual class (0 or 1),\n","ùë¶\n","^\n","y\n","^\n","‚Äã\n","  = predicted probability from the sigmoid function (between 0 and 1).\n"],"metadata":{"id":"aVapuobAdS7J"}},{"cell_type":"markdown","source":["##6. Explain the difference between Lasso, Ridge, and Elastic Net regression?\n"],"metadata":{"id":"ZxfLQn2IdiRd"}},{"cell_type":"markdown","source":["###Ans:- 1. Ridge Regression (L2 Regularization)\n","Concept:\n","\n","```\n","\n","Ridge regression adds a penalty to the sum of the squared values of the model‚Äôs coefficients (L2 regularization).\n","This shrinks the coefficients towards zero but does not make them exactly zero.\n","```\n","###2. Lasso Regression (L1 Regularization)\n","\n","\n","```\n","Lasso regression adds a penalty to the absolute values of coefficients (L1 regularization).\n","This shrinks some coefficients to exactly zero, effectively selecting only the most important features.\n","```\n","\n","##3. Elastic Net Regression (Combination of L1 & L2):\n","\n","\n","```\n","Elastic Net is a combination of Ridge and Lasso regression.\n","It applies both L1 and L2 regularization, meaning it removes some features (like Lasso) but also shrinks others (like Ridge).\n","```\n","\n","\n","\n","\n","\n"],"metadata":{"id":"2JVUswsodzi-"}},{"cell_type":"markdown","source":["##7. When we should use Elastic Net instead of Lasso and Ridge?"],"metadata":{"id":"uOxChL4HeSrF"}},{"cell_type":"markdown","source":["###Ans:- Elastic Net combines both Lasso (L1) and Ridge (L2) regularization, making it useful in situations where neither Lasso nor Ridge alone works well.\n","\n","\n","\n","```\n","1. When Features Are Highly Correlated\n","2. When You Need Both Feature Selection & Shrinkage\n","3. When There Are More Features Than Data Points\n","4. When Lasso is Unstable Due to High Variance\n","\n","```\n","\n"],"metadata":{"id":"kSh9KMN4fLxQ"}},{"cell_type":"markdown","source":["##8. What is the impact of the regurlarization parameter(lambda) in Logistic Regression?"],"metadata":{"id":"r2O7SwPFfalp"}},{"cell_type":"markdown","source":["##Ans:- In Logistic Regression, the regularization parameter (Œª) controls the strength of the penalty applied to the model's coefficients to prevent overfitting or underfitting.\n","\n","\n","\n","```\n","When ùúÜ= 0(No Regularization)\n","When Œª is Small (Weak Regularization)\n","When Œª is Large (Strong Regularization)\n","\n","```\n","\n"],"metadata":{"id":"ax0xasanfvvK"}},{"cell_type":"markdown","source":["##9. What are the key assumptions of Logistic Regression?"],"metadata":{"id":"x1m6dQc-gGQ9"}},{"cell_type":"markdown","source":["###Ans:-  Key assumptions of Logistic Regression are:-\n","\n","\n","```\n","1. The Dependent Variable Must Be Binary or Categorical\n","2. The Relationship Between Independent Variables and Log-Odds is Linear\n","3. No Perfect Multicollinearity Among Independent Variables\n","4. Large Sample Size for Reliable Estimates\n","5. No Extreme Outliers\n","6. Independent Observations (No Autocorrelation)\n","\n","```\n","\n"],"metadata":{"id":"oRLC1yEWgT6f"}},{"cell_type":"markdown","source":["##10. What are some alternatives to Logistic Regression for classification tasks?\n"],"metadata":{"id":"rjUCnnfzgi23"}},{"cell_type":"markdown","source":["###Ans:-While Logistic Regression is a widely used classification algorithm, it has limitations, especially when dealing with nonlinear relationships, large datasets, or complex decision boundaries. Below are some alternative classification algorithms:\n","\n","```\n","1. Decision Tree Classifier\n","2. Random Forest Classifier\n","3. Support Vector Machine\n","4. K-Nearest Neighbors(k-NN)\n","5. Naive Bayes Classifier\n","```\n","\n"],"metadata":{"id":"wlP0ylychMl5"}},{"cell_type":"markdown","source":["##11. What are Classification Evaluation Metrics.\n"],"metadata":{"id":"3nVaqOrahhpZ"}},{"cell_type":"markdown","source":["###Ans:- Classification models predict categories (e.g., spam vs. not spam, disease vs. no disease). To measure how well a model performs, we use classification evaluation metrics.\n","\n","\n","\n","```\n","1. Accuracy\n","2. Precision\n","3. Recall\n","4. F1-Score\n","5. Confusion Matrix\n","6. ROC Curve & AUC\n","```\n","\n"],"metadata":{"id":"S2Rr-wxHhns1"}},{"cell_type":"markdown","source":["##12. How does Class Imbalance affect Logistic Regression?"],"metadata":{"id":"ARmVeCJ_h9OJ"}},{"cell_type":"markdown","source":["###Ans:- Class Imbalance occurs when one class in the dataset has significantly more examples than the other. This is common in real-world scenarios like fraud detection (99% legit vs. 1% fraud) or disease diagnosis (95% healthy vs. 5% sick).\n","\n","\n","\n","```\n","1. Biased Predictions Toward the Majority Class\n","2. Misleading Accuracy (Accuracy Paradox)\n","\n","```\n","\n","###Problem: Logistic Regression (and many ML models) tend to favor the majority class, leading to poor performance on the minority class."],"metadata":{"id":"G3BUOEzbiJAp"}},{"cell_type":"markdown","source":["##13. What is Hyperparameter Tuning in Logistic Regression.\n"],"metadata":{"id":"XQQTqGjnihgf"}},{"cell_type":"markdown","source":["###Ans:- Hyperparameter tuning is the process of optimizing the settings (hyperparameters) of a model to improve its performance.\n","\n","###In Logistic Regression, hyperparameters do not change during training but affect how the model learns."],"metadata":{"id":"cKLhbVQniqUY"}},{"cell_type":"markdown","source":["##14. What are diffrent solvers in Logistic Regression? Which one should be used?"],"metadata":{"id":"gMlQPPRXis8s"}},{"cell_type":"markdown","source":["###Ans:- In Logistic Regression, solvers are optimization algorithms that find the best model parameters (weights). Different solvers work better in different situations, such as small vs. large datasets or L1 vs. L2 regularization.\n","\n","\n","\n","```\n","1. liblinear (Best for Small Datasets)\n","2. lbfgs (Default, Best for Large Datasets)\n","3. newton-cg (Best for High-Dimensional Data)\n","4. sag (Best for Very Large Datasets)\n","5. saga (Best for Large, Sparse Data & L1 Regularization)\n","\n","```\n","\n"],"metadata":{"id":"QwHRFPlJjB5F"}},{"cell_type":"markdown","source":["##15. How is Logistic Regression extended for multiclass classification?"],"metadata":{"id":"Xgfzd-yWjNkD"}},{"cell_type":"markdown","source":["###Ans:- Logistic Regression is naturally designed for binary classification (0 or 1). However, for multiclass classification (3 or more classes), we extend it using different techniques.\n","\n","\n","\n","```\n","üîπ 1. One-vs-Rest (OvR)\n","üîπ 2. One-vs-One (OvO)\n","üîπ 3. Softmax Regression (Multinomial Logistic Regression)\n","```\n","\n"],"metadata":{"id":"gCZM6X_LjbUP"}},{"cell_type":"markdown","source":["##16. What are the advantages and disadvantages of Logistic Regression.\n"],"metadata":{"id":"4z3rvDGIjrHX"}},{"cell_type":"markdown","source":["###Ans:- Logistic Regression is a simple and effective classification algorithm, but it has some limitations. Let‚Äôs explore both its advantages and disadvantages.\n","\n","\n","```\n","Advantages:-\n","  1. Simple & Easy to Implement\n","  2. Works Well with Linearly Separable Data\n","  3. Provides Probability Estimates\n","  4. Fast Training & Interpretation\n","  5. Works Well with Small Datasets\n","  6. Handles Multiple Classes (with Softmax)\n","  7. Regularization Prevents Overfitting\n","\n","Disadvantages:-\n","   1. Assumes Linear Relationship Between Features & Log-Odds\n","   2. 2. Struggles with High-Dimensional Data\n","   3. Sensitive to Outliers\n","   4. Not Suitable for Non-Linear Problems\n","```\n","\n"],"metadata":{"id":"Vw8XYnQdjzK8"}},{"cell_type":"markdown","source":["##17. What are some use cases of Logistic Regression.\n"],"metadata":{"id":"AvpAr7SLkfIR"}},{"cell_type":"markdown","source":["###Ans:- Use Cases of Logistic Regression\n","\n","\n","```\n","üîπ 1. Medical Diagnosis & Disease Prediction\n","üîπ 2. Spam Email Detection\n","üîπ 3. Credit Scoring & Loan Approval\n","üîπ 4. Customer Churn Prediction\n","üîπ 5. Fraud Detection\n","üîπ 6. Employee Attrition Prediction\n","üîπ 7. Voting & Political Predictions\n","üîπ 8. Marketing & Advertisement Targeting\n","üîπ 9. Image Classification\n","üîπ 10. Sentiment Analysis\n","```\n","\n",""],"metadata":{"id":"LZUJxT52kmf3"}},{"cell_type":"markdown","source":["##18. what is the diffrence b/w Softmax Regression and Logistic Regression?"],"metadata":{"id":"n0EgCxSflc7G"}},{"cell_type":"markdown","source":["###Ans:- Diffrence b/w Softmax Regression and Logistic Regression\n","\n","```\n","Logistic Regression:-\n","  1. Binary Classification\n","  2. Sigmoid Function\n","  3. Probability of belonging to one of two classes\n","  4. Class = 1 if probability > 0.5, else Class = 0\n","  Spam detection (Spam/Not Spam), Disease Prediction (Yes/No)\n","\n","Softmax Regression:-\n","  1. Multiclass Classification\n","  2. Softmax Function\n","  3. Probabilities for all classes (sum = 1)\n","  4. Class with highest probability is chosen\n","  5. Handwritten Digit Recognition (0-9), Image Classification\n","```\n","\n"],"metadata":{"id":"sbVQyW4Ilqxj"}},{"cell_type":"markdown","source":["##19. How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification.\n"],"metadata":{"id":"regxrtJAmPLt"}},{"cell_type":"markdown","source":["###Ans:-Choosing Between One-vs-Rest (OvR) and Softmax for Multiclass Classification\n","\n","```\n","OVR:-\n","  Also called One-vs-All (OvA).\n","  Trains one classifier per class, treating it as a binary classification problem against all other classes.\n","  If there are K classes, K separate logistic regression models are trained.\n","  The class with the highest probability is selected.\n","\n","Softmax:-\n","  Also called Multinomial Logistic Regression.\n","  Uses a single model that directly assigns probabilities to all classes at once.\n","  Uses the Softmax function to ensure the sum of probabilities equals 1.\n","  The class with the highest probability is chosen.\n","```\n","\n"],"metadata":{"id":"_YVlQSIumSJa"}},{"cell_type":"markdown","source":["##20. How do we interpret coefficients in Logistic Regression?\n"],"metadata":{"id":"KsVBtzRhmyvC"}},{"cell_type":"markdown","source":["###Ans:- Logistic Regression does not give direct linear relationships like Linear Regression. Instead, the coefficients represent how the independent variables (features) influence the probability of an event occurring.\n","\n","\n","\n","```\n","üîπ 1. Understanding Logistic Regression Equation\n","üîπ 2. Coefficients in Terms of Odds Ratio\n","üîπ 3. Interpreting Logistic Regression Coefficients: Step-by-Step\n","üîπ 4. Interpreting Different Coefficients\n","\n","\n","```\n","\n"],"metadata":{"id":"ndBuRB3qm3RV"}},{"cell_type":"code","source":[],"metadata":{"id":"wdjakQednK2N"},"execution_count":null,"outputs":[]}]}